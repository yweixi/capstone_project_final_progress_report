{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shap\n",
    "import smogn\n",
    "import imblearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score, classification_report, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn.feature_selection import f_regression, f_classif, RFE, VarianceThreshold, chi2, SelectKBest, SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data and remove unwanted columns\n",
    "data = pd.read_excel('augmented sample.xlsx').drop(['index',\n",
    "                                                    'Formation_energy'],\n",
    "                                                    axis=1)\n",
    "data = data.set_index(['Material Composition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into X and y(Energy Above Hull)\n",
    "X = data.drop(['EnergyAboveHull'], axis=1)\n",
    "y = data['EnergyAboveHull']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples 2138 \n",
      "Number of features: 962\n"
     ]
    }
   ],
   "source": [
    "# preview the shape of the dataframe\n",
    "sample_size = X.shape[0]\n",
    "feature_size = X.shape[1]\n",
    "print(\"Number of samples\", sample_size,\n",
    "      \"\\nNumber of features:\", feature_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the y for classification\n",
    "y_clf = np.zeros_like(y)\n",
    "\n",
    "# samples with EnergyAboveHull larger than 40 will be marked as unstable\n",
    "# unstable = 0, stable = 1\n",
    "y_clf = [1*(EAH<=40) for EAH in y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**best parameters for XGB regressor**\n",
    "\n",
    "{'kbest__k': 250, 'model__colsample_bytree': 0.6, 'model__max_depth': 5, 'model__n_estimators': 150, 'pca__n_components': 25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_regressor = xgb.XGBRegressor(colsample_bytree=0.6, \n",
    "                                 max_depth=5, \n",
    "                                 n_estimators=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best pipeline construction\n",
    "xgb_reg_pipeline = Pipeline([\n",
    "    ('variance threshold', VarianceThreshold()),\n",
    "    ('kbest', SelectKBest(f_regression, k=250)),\n",
    "    ('standard_scaler', StandardScaler()), \n",
    "    ('pca', PCA(n_components=25)), \n",
    "    ('model', xgb_regressor)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**best parameters for SVM regressor**\n",
    "\n",
    "{'svr__C': 2260}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_regressor = SVR(C=2260)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best pipeline construction\n",
    "svm_reg_pipeline = Pipeline([\n",
    "    ('variance threshold', VarianceThreshold()),\n",
    "    ('kbest', SelectKBest(f_regression, k=250)),\n",
    "    ('standard_scaler', StandardScaler()), \n",
    "    ('pca', PCA(n_components=25)), \n",
    "    ('model', svm_regressor)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**best parameters for GBDT regressor**\n",
    "\n",
    "{'gradientboostingregressor__alpha': 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbdt_regressor = GradientBoostingRegressor(alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best pipeline construction\n",
    "gbdt_reg_pipeline = Pipeline([\n",
    "    ('variance threshold', VarianceThreshold()),\n",
    "    ('kbest', SelectKBest(f_regression, k=250)),\n",
    "    ('standard_scaler', StandardScaler()), \n",
    "    ('pca', PCA(n_components=25)), \n",
    "    ('model', gbdt_regressor)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10-fold verification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:31:26] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:31:30] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:31:34] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:31:37] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:31:41] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:31:44] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:31:48] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:31:51] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:31:54] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:31:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "fold = 10\n",
    "\n",
    "xgb_reg_avg_mae = []\n",
    "xgb_reg_avg_rmse = []\n",
    "\n",
    "svm_reg_avg_mae = []\n",
    "svm_reg_avg_rmse = []\n",
    "\n",
    "gbdt_reg_avg_mae = []\n",
    "gbdt_reg_avg_rmse = []\n",
    "\n",
    "for i in range(fold):\n",
    "    X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=(1/fold))\n",
    "    \n",
    "    xgb_reg_pipeline.fit(X_trainval, y_trainval)\n",
    "    svm_reg_pipeline.fit(X_trainval, y_trainval)\n",
    "    gbdt_reg_pipeline.fit(X_trainval, y_trainval)\n",
    "    \n",
    "    # for xgb reg\n",
    "    y_pred = xgb_reg_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    xgb_reg_avg_mae.append(mean_absolute_error(y_true, y_pred))\n",
    "    xgb_reg_avg_rmse.append(sqrt(mean_squared_error(y_true, y_pred)))\n",
    "    \n",
    "    # for svm reg\n",
    "    y_pred = svm_reg_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    svm_reg_avg_mae.append(mean_absolute_error(y_true, y_pred))\n",
    "    svm_reg_avg_rmse.append(sqrt(mean_squared_error(y_true, y_pred)))\n",
    "    \n",
    "    # for gbdt reg\n",
    "    y_pred = gbdt_reg_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    gbdt_reg_avg_mae.append(mean_absolute_error(y_true, y_pred))\n",
    "    gbdt_reg_avg_rmse.append(sqrt(mean_squared_error(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**xgb regression results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mae of xgb reg 27.681 ± 7.089\n",
      "average rmse of xgb reg 49.620 ± 23.377\n"
     ]
    }
   ],
   "source": [
    "print('average mae of xgb reg', \n",
    "      '{:.3f}'.format(np.mean(xgb_reg_avg_mae)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(xgb_reg_avg_mae)))\n",
    "print('average rmse of xgb reg', \n",
    "      '{:.3f}'.format(np.mean(xgb_reg_avg_rmse)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(xgb_reg_avg_rmse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**svm regression results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mae of svm reg 19.108 ± 8.125\n",
      "average rmse of svm reg 44.716 ± 34.913\n"
     ]
    }
   ],
   "source": [
    "print('average mae of svm reg', \n",
    "      '{:.3f}'.format(np.mean(svm_reg_avg_mae)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(svm_reg_avg_mae)))\n",
    "print('average rmse of svm reg', \n",
    "      '{:.3f}'.format(np.mean(svm_reg_avg_rmse)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(svm_reg_avg_rmse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gbdt regression results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mae of gbdt reg 34.070 ± 5.984\n",
      "average rmse of gbdt reg 56.986 ± 23.978\n"
     ]
    }
   ],
   "source": [
    "print('average mae of gbdt reg', \n",
    "      '{:.3f}'.format(np.mean(gbdt_reg_avg_mae)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(gbdt_reg_avg_mae)))\n",
    "print('average rmse of gbdt reg', \n",
    "      '{:.3f}'.format(np.mean(gbdt_reg_avg_rmse)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(gbdt_reg_avg_rmse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**best parameters for XGB classifier**\n",
    "\n",
    "{'kbest__k': 450, 'model__colsample_bytree': 0.6, 'model__max_depth': 5, 'model__n_estimators': 650, 'pca__n_components': 50}\n",
    "\n",
    "{'sampling__k_neighbors': 1, 'sampling__m_neighbors': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier = xgb.XGBClassifier(max_depth=5, \n",
    "                                   n_estimators=650, \n",
    "                                   colsample_bytree=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best pipeline construction\n",
    "xgb_clf_pipeline = Pipeline([\n",
    "    ('sampling', BorderlineSMOTE(k_neighbors=1, \n",
    "                                 m_neighbors=1, \n",
    "                                 sampling_strategy='minority')),\n",
    "    ('variance threshold', VarianceThreshold()),\n",
    "    ('kbest', SelectKBest(f_classif, k=450)),\n",
    "    ('standard_scaler', StandardScaler()), \n",
    "    ('pca', PCA(n_components=50)), \n",
    "    ('model', xgb_classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**best parameters for SVM classifier**\n",
    "\n",
    "{'svc__C': 81}\n",
    "\n",
    "{'sampling__k_neighbors': 1, 'sampling__m_neighbors': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = SVC(C=81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best pipeline construction\n",
    "svm_clf_pipeline = Pipeline([\n",
    "    ('sampling', BorderlineSMOTE(k_neighbors=1, \n",
    "                                 m_neighbors=1, \n",
    "                                 sampling_strategy='minority')),\n",
    "    ('variance threshold', VarianceThreshold()),\n",
    "    ('kbest', SelectKBest(f_classif, k=450)),\n",
    "    ('standard_scaler', StandardScaler()), \n",
    "    ('pca', PCA(n_components=50)), \n",
    "    ('model', svm_classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**best parameters for GBDT classifier**\n",
    "\n",
    "{'gradientboostingclassifier__ccp_alpha': 0.0}\n",
    "\n",
    "{'sampling__k_neighbors': 1, 'sampling__m_neighbors': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbdt_classifier = GradientBoostingClassifier(ccp_alpha=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best pipeline construction\n",
    "gbdt_clf_pipeline = Pipeline([\n",
    "    ('sampling', BorderlineSMOTE(k_neighbors=1, \n",
    "                                 m_neighbors=1, \n",
    "                                 sampling_strategy='minority')),\n",
    "    ('variance threshold', VarianceThreshold()),\n",
    "    ('kbest', SelectKBest(f_classif, k=450)),\n",
    "    ('standard_scaler', StandardScaler()), \n",
    "    ('pca', PCA(n_components=50)), \n",
    "    ('model', gbdt_classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10-fold verification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 10\n",
    "\n",
    "xgb_clf_weighted_avg_f1 = []\n",
    "svm_clf_weighted_avg_f1 = []\n",
    "gbdt_clf_weighted_avg_f1 = []\n",
    "\n",
    "for i in range(fold):\n",
    "    X_trainval, X_test, y_trainval, y_test = train_test_split(X, y_clf, test_size=(1/fold))\n",
    "    \n",
    "    xgb_clf_pipeline.fit(X_trainval, y_trainval)\n",
    "    svm_clf_pipeline.fit(X_trainval, y_trainval)\n",
    "    gbdt_clf_pipeline.fit(X_trainval, y_trainval)\n",
    "    \n",
    "    # for xgb clf\n",
    "    y_pred = xgb_clf_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    target_names = ['unstale', 'stable']\n",
    "    report = classification_report(y_true, y_pred, target_names=target_names, output_dict=True)\n",
    "    xgb_clf_weighted_avg_f1.append(report['weighted avg']['f1-score'])\n",
    "    \n",
    "    # for svm clf\n",
    "    y_pred = svm_clf_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    target_names = ['unstale', 'stable']\n",
    "    report = classification_report(y_true, y_pred, target_names=target_names, output_dict=True)\n",
    "    svm_clf_weighted_avg_f1.append(report['weighted avg']['f1-score'])\n",
    "    \n",
    "    # for gbdt clf\n",
    "    y_pred = gbdt_clf_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    target_names = ['unstale', 'stable']\n",
    "    report = classification_report(y_true, y_pred, target_names=target_names, output_dict=True)\n",
    "    gbdt_clf_weighted_avg_f1.append(report['weighted avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**xgb classification results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average weighted f1 score for xgb clf 0.926 ± 0.026\n"
     ]
    }
   ],
   "source": [
    "print('average weighted f1 score for xgb clf', \n",
    "      '{:.3f}'.format(np.mean(xgb_clf_weighted_avg_f1)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(xgb_clf_weighted_avg_f1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**svm classification results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average weighted f1 score for svm clf 0.934 ± 0.023\n"
     ]
    }
   ],
   "source": [
    "print('average weighted f1 score for svm clf', \n",
    "      '{:.3f}'.format(np.mean(svm_clf_weighted_avg_f1)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(svm_clf_weighted_avg_f1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gbdt classification results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average weighted f1 score for gbdt clf 0.901 ± 0.027\n"
     ]
    }
   ],
   "source": [
    "print('average weighted f1 score for gbdt clf', \n",
    "      '{:.3f}'.format(np.mean(gbdt_clf_weighted_avg_f1)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(gbdt_clf_weighted_avg_f1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluation on subgroups**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ba, Sr, Fe, Co subset creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ba_list = []\n",
    "Sr_list = []\n",
    "Fe_list = []\n",
    "Co_list = []\n",
    "for i in range(len(data.index)):\n",
    "    if 'Ba' in data.index[i]:\n",
    "        Ba_list.append(i)\n",
    "    if 'Sr' in data.index[i]:\n",
    "        Sr_list.append(i)\n",
    "    if 'Fe' in data.index[i]:\n",
    "        Fe_list.append(i)\n",
    "    if 'Co' in data.index[i]:\n",
    "        Co_list.append(i)\n",
    "data_Ba = data.iloc[Ba_list]\n",
    "data_Sr = data.iloc[Sr_list]\n",
    "data_Fe = data.iloc[Fe_list]\n",
    "data_Co = data.iloc[Co_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**modeling on Ba**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into X and y(Energy Above Hull)\n",
    "X_ba = data_Ba.drop(['EnergyAboveHull'], axis=1)\n",
    "y_ba = data_Ba['EnergyAboveHull']\n",
    "\n",
    "y_ba_clf = np.zeros_like(y_ba)\n",
    "y_ba_clf = [1*(EAH<=40) for EAH in y_ba]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**regression on Ba**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:33:23] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:33:24] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:33:24] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:33:25] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:33:26] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:33:27] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:33:28] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:33:29] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:33:30] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:33:31] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "fold = 10\n",
    "\n",
    "xgb_reg_avg_mae = []\n",
    "xgb_reg_avg_rmse = []\n",
    "\n",
    "svm_reg_avg_mae = []\n",
    "svm_reg_avg_rmse = []\n",
    "\n",
    "gbdt_reg_avg_mae = []\n",
    "gbdt_reg_avg_rmse = []\n",
    "\n",
    "for i in range(fold):\n",
    "    X_trainval, X_test, y_trainval, y_test = train_test_split(X_ba, y_ba, test_size=(1/fold))\n",
    "    \n",
    "    xgb_reg_pipeline.fit(X_trainval, y_trainval)\n",
    "    svm_reg_pipeline.fit(X_trainval, y_trainval)\n",
    "    gbdt_reg_pipeline.fit(X_trainval, y_trainval)\n",
    "    \n",
    "    # for xgb reg\n",
    "    y_pred = xgb_reg_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    xgb_reg_avg_mae.append(mean_absolute_error(y_true, y_pred))\n",
    "    xgb_reg_avg_rmse.append(sqrt(mean_squared_error(y_true, y_pred)))\n",
    "    \n",
    "    # for svm reg\n",
    "    y_pred = svm_reg_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    svm_reg_avg_mae.append(mean_absolute_error(y_true, y_pred))\n",
    "    svm_reg_avg_rmse.append(sqrt(mean_squared_error(y_true, y_pred)))\n",
    "    \n",
    "    # for gbdt reg\n",
    "    y_pred = gbdt_reg_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    gbdt_reg_avg_mae.append(mean_absolute_error(y_true, y_pred))\n",
    "    gbdt_reg_avg_rmse.append(sqrt(mean_squared_error(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**xgb regression results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mae of xgb reg 34.231 ± 6.286\n",
      "average rmse of xgb reg 61.406 ± 33.880\n"
     ]
    }
   ],
   "source": [
    "print('average mae of xgb reg', \n",
    "      '{:.3f}'.format(np.mean(xgb_reg_avg_mae)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(xgb_reg_avg_mae)))\n",
    "print('average rmse of xgb reg', \n",
    "      '{:.3f}'.format(np.mean(xgb_reg_avg_rmse)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(xgb_reg_avg_rmse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**svm regression results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mae of svm reg 24.652 ± 10.993\n",
      "average rmse of svm reg 58.997 ± 59.246\n"
     ]
    }
   ],
   "source": [
    "print('average mae of svm reg', \n",
    "      '{:.3f}'.format(np.mean(svm_reg_avg_mae)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(svm_reg_avg_mae)))\n",
    "print('average rmse of svm reg', \n",
    "      '{:.3f}'.format(np.mean(svm_reg_avg_rmse)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(svm_reg_avg_rmse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gbdt regression results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mae of gbdt reg 39.236 ± 5.368\n",
      "average rmse of gbdt reg 71.011 ± 33.183\n"
     ]
    }
   ],
   "source": [
    "print('average mae of gbdt reg', \n",
    "      '{:.3f}'.format(np.mean(gbdt_reg_avg_mae)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(gbdt_reg_avg_mae)))\n",
    "print('average rmse of gbdt reg', \n",
    "      '{:.3f}'.format(np.mean(gbdt_reg_avg_rmse)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(gbdt_reg_avg_rmse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classification on Ba**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 10\n",
    "\n",
    "xgb_clf_weighted_avg_f1 = []\n",
    "svm_clf_weighted_avg_f1 = []\n",
    "gbdt_clf_weighted_avg_f1 = []\n",
    "\n",
    "for i in range(fold):\n",
    "    X_trainval, X_test, y_trainval, y_test = train_test_split(X_ba, y_ba_clf, test_size=(1/fold))\n",
    "    \n",
    "    xgb_clf_pipeline.fit(X_trainval, y_trainval)\n",
    "    svm_clf_pipeline.fit(X_trainval, y_trainval)\n",
    "    gbdt_clf_pipeline.fit(X_trainval, y_trainval)\n",
    "    \n",
    "    # for xgb clf\n",
    "    y_pred = xgb_clf_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    target_names = ['unstale', 'stable']\n",
    "    report = classification_report(y_true, y_pred, target_names=target_names, output_dict=True)\n",
    "    xgb_clf_weighted_avg_f1.append(report['weighted avg']['f1-score'])\n",
    "    \n",
    "    # for svm clf\n",
    "    y_pred = svm_clf_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    target_names = ['unstale', 'stable']\n",
    "    report = classification_report(y_true, y_pred, target_names=target_names, output_dict=True)\n",
    "    svm_clf_weighted_avg_f1.append(report['weighted avg']['f1-score'])\n",
    "    \n",
    "    # for gbdt clf\n",
    "    y_pred = gbdt_clf_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    target_names = ['unstale', 'stable']\n",
    "    report = classification_report(y_true, y_pred, target_names=target_names, output_dict=True)\n",
    "    gbdt_clf_weighted_avg_f1.append(report['weighted avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**xgb classification results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average weighted f1 score for xgb clf 0.903 ± 0.101\n"
     ]
    }
   ],
   "source": [
    "print('average weighted f1 score for xgb clf', \n",
    "      '{:.3f}'.format(np.mean(xgb_clf_weighted_avg_f1)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(xgb_clf_weighted_avg_f1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**svm classification results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average weighted f1 score for svm clf 0.919 ± 0.043\n"
     ]
    }
   ],
   "source": [
    "print('average weighted f1 score for svm clf', \n",
    "      '{:.3f}'.format(np.mean(svm_clf_weighted_avg_f1)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(svm_clf_weighted_avg_f1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gbdt classification results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average weighted f1 score for gbdt clf 0.897 ± 0.082\n"
     ]
    }
   ],
   "source": [
    "print('average weighted f1 score for gbdt clf', \n",
    "      '{:.3f}'.format(np.mean(gbdt_clf_weighted_avg_f1)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(gbdt_clf_weighted_avg_f1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**modeling on Sr**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into X and y(Energy Above Hull)\n",
    "X_sr = data_Sr.drop(['EnergyAboveHull'], axis=1)\n",
    "y_sr = data_Sr['EnergyAboveHull']\n",
    "\n",
    "y_sr_clf = np.zeros_like(y_sr)\n",
    "y_sr_clf = [1*(EAH<=40) for EAH in y_sr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**regression on Sr**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:33:55] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:33:56] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:33:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:33:58] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:33:58] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:33:59] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:34:00] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:34:01] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:34:02] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:34:02] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "fold = 10\n",
    "\n",
    "xgb_reg_avg_mae = []\n",
    "xgb_reg_avg_rmse = []\n",
    "\n",
    "svm_reg_avg_mae = []\n",
    "svm_reg_avg_rmse = []\n",
    "\n",
    "gbdt_reg_avg_mae = []\n",
    "gbdt_reg_avg_rmse = []\n",
    "\n",
    "for i in range(fold):\n",
    "    X_trainval, X_test, y_trainval, y_test = train_test_split(X_sr, y_sr, test_size=(1/fold))\n",
    "    \n",
    "    xgb_reg_pipeline.fit(X_trainval, y_trainval)\n",
    "    svm_reg_pipeline.fit(X_trainval, y_trainval)\n",
    "    gbdt_reg_pipeline.fit(X_trainval, y_trainval)\n",
    "    \n",
    "    # for xgb reg\n",
    "    y_pred = xgb_reg_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    xgb_reg_avg_mae.append(mean_absolute_error(y_true, y_pred))\n",
    "    xgb_reg_avg_rmse.append(sqrt(mean_squared_error(y_true, y_pred)))\n",
    "    \n",
    "    # for svm reg\n",
    "    y_pred = svm_reg_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    svm_reg_avg_mae.append(mean_absolute_error(y_true, y_pred))\n",
    "    svm_reg_avg_rmse.append(sqrt(mean_squared_error(y_true, y_pred)))\n",
    "    \n",
    "    # for gbdt reg\n",
    "    y_pred = gbdt_reg_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    gbdt_reg_avg_mae.append(mean_absolute_error(y_true, y_pred))\n",
    "    gbdt_reg_avg_rmse.append(sqrt(mean_squared_error(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**xgb regression results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mae of xgb reg 21.998 ± 4.295\n",
      "average rmse of xgb reg 33.653 ± 14.821\n"
     ]
    }
   ],
   "source": [
    "print('average mae of xgb reg', \n",
    "      '{:.3f}'.format(np.mean(xgb_reg_avg_mae)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(xgb_reg_avg_mae)))\n",
    "print('average rmse of xgb reg', \n",
    "      '{:.3f}'.format(np.mean(xgb_reg_avg_rmse)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(xgb_reg_avg_rmse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**svm regression results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mae of svm reg 14.350 ± 5.143\n",
      "average rmse of svm reg 25.892 ± 16.751\n"
     ]
    }
   ],
   "source": [
    "print('average mae of svm reg', \n",
    "      '{:.3f}'.format(np.mean(svm_reg_avg_mae)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(svm_reg_avg_mae)))\n",
    "print('average rmse of svm reg', \n",
    "      '{:.3f}'.format(np.mean(svm_reg_avg_rmse)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(svm_reg_avg_rmse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gbdt regression results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mae of gbdt reg 24.881 ± 4.002\n",
      "average rmse of gbdt reg 36.115 ± 15.020\n"
     ]
    }
   ],
   "source": [
    "print('average mae of gbdt reg', \n",
    "      '{:.3f}'.format(np.mean(gbdt_reg_avg_mae)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(gbdt_reg_avg_mae)))\n",
    "print('average rmse of gbdt reg', \n",
    "      '{:.3f}'.format(np.mean(gbdt_reg_avg_rmse)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(gbdt_reg_avg_rmse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classification on Sr**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 10\n",
    "\n",
    "xgb_clf_weighted_avg_f1 = []\n",
    "svm_clf_weighted_avg_f1 = []\n",
    "gbdt_clf_weighted_avg_f1 = []\n",
    "\n",
    "for i in range(fold):\n",
    "    X_trainval, X_test, y_trainval, y_test = train_test_split(X_sr, y_sr_clf, test_size=(1/fold))\n",
    "    \n",
    "    xgb_clf_pipeline.fit(X_trainval, y_trainval)\n",
    "    svm_clf_pipeline.fit(X_trainval, y_trainval)\n",
    "    gbdt_clf_pipeline.fit(X_trainval, y_trainval)\n",
    "    \n",
    "    # for xgb clf\n",
    "    y_pred = xgb_clf_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    target_names = ['unstale', 'stable']\n",
    "    report = classification_report(y_true, y_pred, target_names=target_names, output_dict=True)\n",
    "    xgb_clf_weighted_avg_f1.append(report['weighted avg']['f1-score'])\n",
    "    \n",
    "    # for svm clf\n",
    "    y_pred = svm_clf_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    target_names = ['unstale', 'stable']\n",
    "    report = classification_report(y_true, y_pred, target_names=target_names, output_dict=True)\n",
    "    svm_clf_weighted_avg_f1.append(report['weighted avg']['f1-score'])\n",
    "    \n",
    "    # for gbdt clf\n",
    "    y_pred = gbdt_clf_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    target_names = ['unstale', 'stable']\n",
    "    report = classification_report(y_true, y_pred, target_names=target_names, output_dict=True)\n",
    "    gbdt_clf_weighted_avg_f1.append(report['weighted avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**xgb classification results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average weighted f1 score for xgb clf 0.958 ± 0.040\n"
     ]
    }
   ],
   "source": [
    "print('average weighted f1 score for xgb clf', \n",
    "      '{:.3f}'.format(np.mean(xgb_clf_weighted_avg_f1)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(xgb_clf_weighted_avg_f1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**svm classification results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average weighted f1 score for svm clf 0.945 ± 0.033\n"
     ]
    }
   ],
   "source": [
    "print('average weighted f1 score for svm clf', \n",
    "      '{:.3f}'.format(np.mean(svm_clf_weighted_avg_f1)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(svm_clf_weighted_avg_f1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gbdt classification results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average weighted f1 score for gbdt clf 0.945 ± 0.057\n"
     ]
    }
   ],
   "source": [
    "print('average weighted f1 score for gbdt clf', \n",
    "      '{:.3f}'.format(np.mean(gbdt_clf_weighted_avg_f1)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(gbdt_clf_weighted_avg_f1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**modeling on Fe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into X and y(Energy Above Hull)\n",
    "X_fe = data_Fe.drop(['EnergyAboveHull'], axis=1)\n",
    "y_fe = data_Fe['EnergyAboveHull']\n",
    "\n",
    "y_fe_clf = np.zeros_like(y_fe)\n",
    "y_fe_clf = [1*(EAH<=40) for EAH in y_fe]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**regression on Fe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:34:23] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:34:23] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:34:24] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:34:25] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:34:26] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:34:26] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:34:27] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:34:28] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:34:29] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:34:30] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "fold = 10\n",
    "\n",
    "xgb_reg_avg_mae = []\n",
    "xgb_reg_avg_rmse = []\n",
    "\n",
    "svm_reg_avg_mae = []\n",
    "svm_reg_avg_rmse = []\n",
    "\n",
    "gbdt_reg_avg_mae = []\n",
    "gbdt_reg_avg_rmse = []\n",
    "\n",
    "for i in range(fold):\n",
    "    X_trainval, X_test, y_trainval, y_test = train_test_split(X_fe, y_fe, test_size=(1/fold))\n",
    "    \n",
    "    xgb_reg_pipeline.fit(X_trainval, y_trainval)\n",
    "    svm_reg_pipeline.fit(X_trainval, y_trainval)\n",
    "    gbdt_reg_pipeline.fit(X_trainval, y_trainval)\n",
    "    \n",
    "    # for xgb reg\n",
    "    y_pred = xgb_reg_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    xgb_reg_avg_mae.append(mean_absolute_error(y_true, y_pred))\n",
    "    xgb_reg_avg_rmse.append(sqrt(mean_squared_error(y_true, y_pred)))\n",
    "    \n",
    "    # for svm reg\n",
    "    y_pred = svm_reg_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    svm_reg_avg_mae.append(mean_absolute_error(y_true, y_pred))\n",
    "    svm_reg_avg_rmse.append(sqrt(mean_squared_error(y_true, y_pred)))\n",
    "    \n",
    "    # for gbdt reg\n",
    "    y_pred = gbdt_reg_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    gbdt_reg_avg_mae.append(mean_absolute_error(y_true, y_pred))\n",
    "    gbdt_reg_avg_rmse.append(sqrt(mean_squared_error(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**xgb regression results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mae of xgb reg 33.297 ± 14.681\n",
      "average rmse of xgb reg 60.902 ± 52.497\n"
     ]
    }
   ],
   "source": [
    "print('average mae of xgb reg', \n",
    "      '{:.3f}'.format(np.mean(xgb_reg_avg_mae)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(xgb_reg_avg_mae)))\n",
    "print('average rmse of xgb reg', \n",
    "      '{:.3f}'.format(np.mean(xgb_reg_avg_rmse)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(xgb_reg_avg_rmse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**svm regression results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mae of svm reg 25.007 ± 13.131\n",
      "average rmse of svm reg 59.281 ± 64.438\n"
     ]
    }
   ],
   "source": [
    "print('average mae of svm reg', \n",
    "      '{:.3f}'.format(np.mean(svm_reg_avg_mae)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(svm_reg_avg_mae)))\n",
    "print('average rmse of svm reg', \n",
    "      '{:.3f}'.format(np.mean(svm_reg_avg_rmse)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(svm_reg_avg_rmse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gbdt regression results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mae of gbdt reg 39.920 ± 11.089\n",
      "average rmse of gbdt reg 71.553 ± 48.050\n"
     ]
    }
   ],
   "source": [
    "print('average mae of gbdt reg', \n",
    "      '{:.3f}'.format(np.mean(gbdt_reg_avg_mae)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(gbdt_reg_avg_mae)))\n",
    "print('average rmse of gbdt reg', \n",
    "      '{:.3f}'.format(np.mean(gbdt_reg_avg_rmse)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(gbdt_reg_avg_rmse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classification on Fe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 10\n",
    "\n",
    "xgb_clf_weighted_avg_f1 = []\n",
    "svm_clf_weighted_avg_f1 = []\n",
    "gbdt_clf_weighted_avg_f1 = []\n",
    "\n",
    "for i in range(fold):\n",
    "    X_trainval, X_test, y_trainval, y_test = train_test_split(X_fe, y_fe_clf, test_size=(1/fold))\n",
    "    \n",
    "    xgb_clf_pipeline.fit(X_trainval, y_trainval)\n",
    "    svm_clf_pipeline.fit(X_trainval, y_trainval)\n",
    "    gbdt_clf_pipeline.fit(X_trainval, y_trainval)\n",
    "    \n",
    "    # for xgb clf\n",
    "    y_pred = xgb_clf_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    target_names = ['unstale', 'stable']\n",
    "    report = classification_report(y_true, y_pred, target_names=target_names, output_dict=True)\n",
    "    xgb_clf_weighted_avg_f1.append(report['weighted avg']['f1-score'])\n",
    "    \n",
    "    # for svm clf\n",
    "    y_pred = svm_clf_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    target_names = ['unstale', 'stable']\n",
    "    report = classification_report(y_true, y_pred, target_names=target_names, output_dict=True)\n",
    "    svm_clf_weighted_avg_f1.append(report['weighted avg']['f1-score'])\n",
    "    \n",
    "    # for gbdt clf\n",
    "    y_pred = gbdt_clf_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    target_names = ['unstale', 'stable']\n",
    "    report = classification_report(y_true, y_pred, target_names=target_names, output_dict=True)\n",
    "    gbdt_clf_weighted_avg_f1.append(report['weighted avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**xgb classifcation results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average weighted f1 score for xgb clf 0.925 ± 0.044\n"
     ]
    }
   ],
   "source": [
    "print('average weighted f1 score for xgb clf', \n",
    "      '{:.3f}'.format(np.mean(xgb_clf_weighted_avg_f1)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(xgb_clf_weighted_avg_f1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**svm classifcation results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average weighted f1 score for svm clf 0.929 ± 0.061\n"
     ]
    }
   ],
   "source": [
    "print('average weighted f1 score for svm clf', \n",
    "      '{:.3f}'.format(np.mean(svm_clf_weighted_avg_f1)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(svm_clf_weighted_avg_f1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gbdt classifcation results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average weighted f1 score for gbdt clf 0.910 ± 0.065\n"
     ]
    }
   ],
   "source": [
    "print('average weighted f1 score for gbdt clf', \n",
    "      '{:.3f}'.format(np.mean(gbdt_clf_weighted_avg_f1)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(gbdt_clf_weighted_avg_f1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**modeling on Co**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into X and y(Energy Above Hull)\n",
    "X_co = data_Co.drop(['EnergyAboveHull'], axis=1)\n",
    "y_co = data_Co['EnergyAboveHull']\n",
    "\n",
    "y_co_clf = np.zeros_like(y_co)\n",
    "y_co_clf = [1*(EAH<=40) for EAH in y_co]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**regression on Co**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:34:53] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:34:54] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:34:55] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:34:56] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:34:56] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:34:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:34:58] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:34:58] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:34:59] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:35:00] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "fold = 10\n",
    "\n",
    "xgb_reg_avg_mae = []\n",
    "xgb_reg_avg_rmse = []\n",
    "\n",
    "svm_reg_avg_mae = []\n",
    "svm_reg_avg_rmse = []\n",
    "\n",
    "gbdt_reg_avg_mae = []\n",
    "gbdt_reg_avg_rmse = []\n",
    "\n",
    "for i in range(fold):\n",
    "    X_trainval, X_test, y_trainval, y_test = train_test_split(X_co, y_co, test_size=(1/fold))\n",
    "    \n",
    "    xgb_reg_pipeline.fit(X_trainval, y_trainval)\n",
    "    svm_reg_pipeline.fit(X_trainval, y_trainval)\n",
    "    gbdt_reg_pipeline.fit(X_trainval, y_trainval)\n",
    "    \n",
    "    # for xgb reg\n",
    "    y_pred = xgb_reg_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    xgb_reg_avg_mae.append(mean_absolute_error(y_true, y_pred))\n",
    "    xgb_reg_avg_rmse.append(sqrt(mean_squared_error(y_true, y_pred)))\n",
    "    \n",
    "    # for svm reg\n",
    "    y_pred = svm_reg_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    svm_reg_avg_mae.append(mean_absolute_error(y_true, y_pred))\n",
    "    svm_reg_avg_rmse.append(sqrt(mean_squared_error(y_true, y_pred)))\n",
    "    \n",
    "    # for gbdt reg\n",
    "    y_pred = gbdt_reg_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    gbdt_reg_avg_mae.append(mean_absolute_error(y_true, y_pred))\n",
    "    gbdt_reg_avg_rmse.append(sqrt(mean_squared_error(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**xgb regression results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mae of xgb reg 20.122 ± 3.344\n",
      "average rmse of xgb reg 29.124 ± 6.722\n"
     ]
    }
   ],
   "source": [
    "print('average mae of xgb reg', \n",
    "      '{:.3f}'.format(np.mean(xgb_reg_avg_mae)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(xgb_reg_avg_mae)))\n",
    "print('average rmse of xgb reg', \n",
    "      '{:.3f}'.format(np.mean(xgb_reg_avg_rmse)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(xgb_reg_avg_rmse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**svm regression results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mae of svm reg 17.777 ± 4.117\n",
      "average rmse of svm reg 28.272 ± 9.121\n"
     ]
    }
   ],
   "source": [
    "print('average mae of svm reg', \n",
    "      '{:.3f}'.format(np.mean(svm_reg_avg_mae)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(svm_reg_avg_mae)))\n",
    "print('average rmse of svm reg', \n",
    "      '{:.3f}'.format(np.mean(svm_reg_avg_rmse)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(svm_reg_avg_rmse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gbdt regression results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mae of gbdt reg 22.331 ± 4.943\n",
      "average rmse of gbdt reg 30.465 ± 7.595\n"
     ]
    }
   ],
   "source": [
    "print('average mae of gbdt reg', \n",
    "      '{:.3f}'.format(np.mean(gbdt_reg_avg_mae)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(gbdt_reg_avg_mae)))\n",
    "print('average rmse of gbdt reg', \n",
    "      '{:.3f}'.format(np.mean(gbdt_reg_avg_rmse)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(gbdt_reg_avg_rmse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classification on Co**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 10\n",
    "\n",
    "xgb_clf_weighted_avg_f1 = []\n",
    "svm_clf_weighted_avg_f1 = []\n",
    "gbdt_clf_weighted_avg_f1 = []\n",
    "\n",
    "for i in range(fold):\n",
    "    X_trainval, X_test, y_trainval, y_test = train_test_split(X_co, y_co_clf, test_size=(1/fold))\n",
    "    \n",
    "    xgb_clf_pipeline.fit(X_trainval, y_trainval)\n",
    "    svm_clf_pipeline.fit(X_trainval, y_trainval)\n",
    "    gbdt_clf_pipeline.fit(X_trainval, y_trainval)\n",
    "    \n",
    "    # for xgb clf\n",
    "    y_pred = xgb_clf_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    target_names = ['unstale', 'stable']\n",
    "    report = classification_report(y_true, y_pred, target_names=target_names, output_dict=True)\n",
    "    xgb_clf_weighted_avg_f1.append(report['weighted avg']['f1-score'])\n",
    "    \n",
    "    # for svm clf\n",
    "    y_pred = svm_clf_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    target_names = ['unstale', 'stable']\n",
    "    report = classification_report(y_true, y_pred, target_names=target_names, output_dict=True)\n",
    "    svm_clf_weighted_avg_f1.append(report['weighted avg']['f1-score'])\n",
    "    \n",
    "    # for gbdt clf\n",
    "    y_pred = gbdt_clf_pipeline.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    target_names = ['unstale', 'stable']\n",
    "    report = classification_report(y_true, y_pred, target_names=target_names, output_dict=True)\n",
    "    gbdt_clf_weighted_avg_f1.append(report['weighted avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**xgb classification results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average weighted f1 score for xgb clf 0.917 ± 0.073\n"
     ]
    }
   ],
   "source": [
    "print('average weighted f1 score for xgb clf', \n",
    "      '{:.3f}'.format(np.mean(xgb_clf_weighted_avg_f1)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(xgb_clf_weighted_avg_f1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**svm classification results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average weighted f1 score for svm clf 0.922 ± 0.089\n"
     ]
    }
   ],
   "source": [
    "print('average weighted f1 score for svm clf', \n",
    "      '{:.3f}'.format(np.mean(svm_clf_weighted_avg_f1)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(svm_clf_weighted_avg_f1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gbdt classification results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average weighted f1 score for gbdt clf 0.908 ± 0.095\n"
     ]
    }
   ],
   "source": [
    "print('average weighted f1 score for gbdt clf', \n",
    "      '{:.3f}'.format(np.mean(gbdt_clf_weighted_avg_f1)), \n",
    "      '±', \n",
    "      '{:.3f}'.format(2*np.std(gbdt_clf_weighted_avg_f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
